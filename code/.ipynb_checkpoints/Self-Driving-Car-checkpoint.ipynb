{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tqdm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5f8da7f26b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tqdm"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm.pandas()\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, merge, Activation\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set some constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data already saved from the simulator, it's time to process it and train a model using it !\n",
    "Just run the cells below in order to set the necessary paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (75, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../simulator_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = data_path + \"IMG/\"\n",
    "csv_path = data_path + \"driving_log.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read the CSV file the Udacity Simulator has saved and process the information there. \n",
    "\n",
    "Try using the **read_csv** method shown below to read the CSV file containing the images information. Remember that the column names are:\n",
    "1. center\n",
    "2. left\n",
    "3. right\n",
    "4. steering\n",
    "5. throttle\n",
    "6. reverse\n",
    "7. speed\n",
    "\n",
    "Name your variable ***data_df***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read a csv file into a Pandas Dataframe using the function read_csv.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(PATH, names = [LIST_OF_COLUMN_NAMES)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/read_csv_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep columns of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep just the columns that are interesting to us, namely\n",
    "1. **features columns** ( which contain the information that we will use to predict our target variable). These are\n",
    "    * **center**\n",
    "    * **left**\n",
    "    * **right**\n",
    "    \n",
    "    \n",
    "2. **label column** ( which contain the information we will want to predict ). It is\n",
    "    * **steering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you can select just a subset of columns of a DataFrame and you can assign it to the original DataFrame variable\n",
    "\n",
    "```python\n",
    "df = df[LIST_OF_COLUMN_NAMES]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/keep_columns_of_interest_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearange columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 3 columns (\"center\", \"left\" and \"right\") which contain paths to images, taken from different angles of the car. For our purpose, it would be useful to take these columns and merge them into a single one, as we'll have more data to train on.\n",
    "\n",
    "For this, we have provided a helping function **rearrange_columns**, as the task is non trivial. If you're curios, please look over it and try to understand what it does.\n",
    "\n",
    "Call the function below like in the Code Example section and assign the result back to the same variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rearrange_columns(data_df):\n",
    "    rearranged_df_list = []\n",
    "    \n",
    "    for col in ['center','left','right']:\n",
    "        partial_df = data_df[[col] + ['steering']]\n",
    "        \n",
    "        partial_df = partial_df.rename(columns = {col:'img_path'})\n",
    "        \n",
    "        rearranged_df_list.append(partial_df)\n",
    "        \n",
    "    rearranged_df = pd.concat(rearranged_df_list)\n",
    "    \n",
    "    return rearranged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sufficient to call the provided function like to\n",
    "\n",
    "```python\n",
    "df = rearrange_columns(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/rearange_columns_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the shape of the new DataFrame , now we have 3 times more images ! That will be really useful later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change relative img path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look in the CSV files, all the paths to the actual images are paths on your local machine !\n",
    "\n",
    "Now, they are no use to us, because we are running the Jupyter Notebook within the Docker container you just created, and the container's filesystem is completely independent of the filesystem of the machine we are running it on.\n",
    "\n",
    "But as you remember, we started the container passing the ***-v*** parameter\n",
    "\n",
    "```\n",
    "sudo docker run -d --name clujai -it -p 8887:8888 -p 4567:4567 -v /Users/bogdang/ComputerScience/cluj-ai/:/home/docker/fastai-courses/deeplearning1/nbs/clujai_workspace deeprig/fastai-course-1\n",
    "```\n",
    "\n",
    "This parameter allows us to mount a local filesystem folder to one inside the container. We can take advantage of this in order to fix all the paths of the images, as the images folder is visible in the container due to the before mentioned mount operation\n",
    "\n",
    "What we'll need to do is to apply a special ***path_convertion*** function to each path. Luckily the DataFrame API allows us to apply a certain function to each element of a certain column. We have provided the ***path_conversion*** function below and all you need to do is use it !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_conversion(path):\n",
    "    return data_path + \"IMG/\" + os.path.basename(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can apply a function to a DataFrame column and assign the returned values back to the column itself:\n",
    "\n",
    "```python\n",
    "df.loc[:,COLUMN_NAME] = data_df.loc[:,COLUMN_NAME].apply(CUSTOM_FUNCTION_NAME)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/change_relative_img_path_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training any type of ML model, it is very important to ***shuffle*** your data. This can lead to a smoother learning process and yield superior results.\n",
    "\n",
    "So let's do just that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll leverage the existing method from the [sklearn](path) module. We'll pass it a seed in order to get the same shuffling every time we run the code. This is important, otherwiese we might get different training results every time we run the code. This is obviously something undesirable/\n",
    "\n",
    "```python\n",
    "df = shuffle(df,random_state = 0)\n",
    "```\n",
    "\n",
    "Shuffle the data and assign it back to the same varible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/shuffle_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to read the images themselves. We can use the DataFrame API's ***apply*** method again, in order to take a path and return the image. The single difference now is that we will create another column, named ***img***, instead of overwriting the same column.\n",
    "\n",
    "We have provided some helper method here as well. Namely, you will need to use the ***read_img*** function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    return img[60:-25, :, :] \n",
    "\n",
    "def read_image(path):\n",
    "    img = np.asarray(PIL.Image.open(path)) # read image with PIL then transform it into a NumPy arry\n",
    "    img = crop(img) # cropping the image, as we are only interested in the road\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As might take a while, it would be useful if we could have some kind of a progress bar. Luckily, there is a method named ***progress_apply*** which provided us with exactly that:\n",
    "\n",
    "```python\n",
    "df.loc[:,DST_COLUMN_NAME] = data_df.loc[:,SRC_COLUMN_NAME].progress_apply(CUSTOM_FUNCTION_NAME)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/read_images_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always useful to visualize your data in order to make sure that you're passing to the ML model exactly what you want. So let's do just that ! \n",
    "\n",
    "We have provided a helper function ***plot_data*** to which you need to pass your DataFrame and the number of images to display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(data_df, nr_images):\n",
    "\n",
    "    for _,row in  data_df.iloc[:nr_images].iterrows():\n",
    "\n",
    "        plt.imshow(row['img'])\n",
    "        plt.figure()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "No code example here. Just call the function with the right parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/visualize_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to help our network perform the task we want it to perform, it would be useful to get as much data as possible. In our case, we could just manually play for a few more laps but for other image processing tasks, we might not have the luxury of being able to generate infinite training data\n",
    "\n",
    "Therefore we could be inventive. One trick we could to would to be horizontally rotate the images while subsequently reverse it's corresponding steering value (because a left turn now suddenly becomes a right turn)\n",
    "\n",
    "You will have to perform more steps at this point, but it will be worth it ! There is only 1 line of code that needs to be written for every step.\n",
    "\n",
    "1. ***Step 1***\n",
    "    * Create a copy of our DataFrame named ***augmented_df***. See how you can do this in the Code Example section\n",
    "2. ***Step 2***\n",
    "    * Reverse the images in the augmented_df using DataFrame API's apply method. You can apply the provided helper function named ***flip_image***. Do NOT create another column but instead overwrite the existing column.\n",
    "3. ***Step 3***\n",
    "    * Use the same technique in order to reverse the steering. We have provided a helper function for this as well named ***reverse_steering***. Do NOT create another column but instead overwrite the existing column.\n",
    "4. ***Step 4***\n",
    "    * Concatenate the original DataFrame with the augmented one and assign it back to the same variable. In the Code Example section you can see how this can be done.\n",
    "5. ***Step 5***\n",
    "    * After concatenation, you will have the the two DataFrames stacked one above the other. It would be best if we shuffle the resulting DataFrame again in order to mix the values up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_image(img):\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "def reverse_steering(s):\n",
    "    return -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to copy a DataFrame is by using the ***copy*** method from the DataFrame API.\n",
    "\n",
    "```python\n",
    "df_2 = df_1.copy()\n",
    "```\n",
    "\n",
    "\n",
    "Here's how you can concatenate two DataFrames and assign it to one of the variables again. We will use Pandas's ***concat*** method\n",
    "\n",
    "```python\n",
    "df_1 = pd.concat([df_1,df_2])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/augment_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went fine, you should now have 2 times more data !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our augmented data looks like, just to make sure that everything went ok with our code. Use the ***plot_data*** method presented above, but this time pass the ***augmented_df***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/visualize_augmented_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data in train / test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we need to split the data in ***train dataset*** and ***test dataset***. \n",
    "\n",
    "Please choose a certain percentage to keep in your training set (we recommend somewhere between 0.65 and 0.85) and use the provided ***train_test_split*** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(data_df, train_percentage):\n",
    "    nr_train = int(train_percentage * len(data_df))\n",
    "    train_df = data_df[:nr_train]\n",
    "    test_df = data_df[nr_train:]\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the provided helper function like this:\n",
    "\n",
    "```python\n",
    "train_df, test_df = train_test_split(df, 0.8)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/train_test_split_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for model ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most (if not all) of Deep Learning frameworks written in Python expect data in the form of NumPy arrays. For those who are unfamiliar with it, NumPy is the de facto library to use for scientific computing in Python.\n",
    "\n",
    "So far, we have used Pandas to manage our data, but now it is time to change it to NumPy. In each of our two DataFrames, we currently have two columns ***img*** which represent the features and ***steering*** which represents the label. Therefore we will need to convert each column into a NumPy Array.\n",
    "\n",
    "Each NumPy array will have a different shape:\n",
    "\n",
    "1. Features\n",
    "    * On each DF row, we have an image having as shape (75,320,3) representing the height, width and number of color channels of each image\n",
    "    * We will concatenate all the images in the DataFrame together by stacking them on top of each other. For example, if our DataFrame would have 100 images in it, we will end up with a NumPy array having the shape (100,75,320,3)\n",
    "    \n",
    "2. Label\n",
    "    * On each DF row, we have a single integer\n",
    "    * We will concatenate all the integers together. For example, if our DataFrame would have 100 values in it, we will end up with a NumPy array having the shape (100,)\n",
    "\n",
    "So what you need to do is call the provided helper function called ***get_formated_data*** on both the training and the testing DataFrames and get their corresponding NumPy arrays.\n",
    "    \n",
    "***Side Note***\n",
    "\n",
    "The way Keras is configured in this Docker container (it can be changed later on) is that it expectes images shape to be a little different when being fed into the model. More specifically, instead of images having the color channels last \n",
    "\n",
    "``` \n",
    "(Height,Width,Color Channels)\n",
    "``` \n",
    "\n",
    "it expects them to be first, like this \n",
    "\n",
    "```\n",
    "(Color Channels, Height,Width)\n",
    "```\n",
    "    \n",
    "We have already handled this in the provided helper function, but it's good for you to be aware of it.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_formated_data(data_df):\n",
    "    imgs = np.stack(data_df['img'].tolist())\n",
    "    labels = np.stack(data_df['steering'].tolist())\n",
    "    \n",
    "    imgs = np.transpose(imgs,(0,3,1,2))\n",
    "    return imgs, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to use the provided helper function is \n",
    "\n",
    "```python\n",
    "imgs_array, labels_array = get_formated_data(df)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/format_data_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_imgs.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_imgs.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the data, it's time to create the model. If you look at the architecture of the model we're about to create in the ***get_model*** provided helper function, you'll notice a few things\n",
    "1. We're treating this problem as a regression problem, aka trying to predict the continuous \"steering\" value\n",
    "2. There is nothing fancy about this architecture. It's a classic mix of Convolutional Layers followed by Batch Normalization Layers and then some Dense (fully connected) ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://image.slidesharecdn.com/case-study-of-cnn-160501201532/95/case-study-of-convolutional-neural-network-3-638.jpg?cb=1462133741\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://image.slidesharecdn.com/case-study-of-cnn-160501201532/95/case-study-of-convolutional-neural-network-3-638.jpg?cb=1462133741\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What it does***\n",
    "\n",
    "\n",
    "***Advantages***\n",
    "1. Speeds up training\n",
    "2. Reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://r2rt.com/static/images/BN_output_23_0.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://r2rt.com/static/images/BN_output_23_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What it does***\n",
    "\n",
    "\n",
    "***Advantages***\n",
    "1. Reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/dropout.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/dropout.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Paper*** : https://arxiv.org/abs/1511.07289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://machinelearningonlinedotblog.files.wordpress.com/2017/06/relu-and-elu.png?w=739\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://machinelearningonlinedotblog.files.wordpress.com/2017/06/relu-and-elu.png?w=739\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Fun Fact) Why you should never use Sigmoid as your activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*XxxiA0jJvPrHEJHD4z893g.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/1600/1*XxxiA0jJvPrHEJHD4z893g.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main reasons why you never want your sigmoid as your activation function is because the gradients can very easily vanish. The reason for that is very simple:\n",
    "\n",
    "When the sigmoid has very high/low values, the derivative in that points is very close to 0, which means that the gradient is close to 0 (aka vanishes) and your weights don't get updated anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://ronny.rest/media/blog/2017/2017_08_10_sigmoid/sigmoid_and_derivative_plot.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://ronny.rest/media/blog/2017/2017_08_10_sigmoid/sigmoid_and_derivative_plot.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided code\n",
    "\n",
    "As you can see, defining a model architecture in Keras is really simple and straightforward. You just create a **Sequential** model and then you add layers to it. After that, you define the loss function, in our case it will be \"mean_squared_error\" and the optimizer, for which we chose Adam.\n",
    "\n",
    "The network chosen has been initially presented here https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5-1.0, input_shape=(3,) + img_size, output_shape = (3,) + img_size))\n",
    "    model.add(Convolution2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    model.add(Convolution2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    model.add(Convolution2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "In order to create the model, just call\n",
    "\n",
    "```python\n",
    "model = get_model()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/model_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the network architecture in two ways.\n",
    "\n",
    "The first of one is using the **summary** function, which prints the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one is by creating a scheme of the layers, which might be easier to understand, in cases where the network's architecture is more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready now to train our neural network. You just need to use the ***fit*** function like in the coding example, and you're good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to call the ***fit*** function you need to pass a few simple parameters\n",
    "\n",
    "```python\n",
    "    model.fit( TRAIN_IMAGES, \n",
    "               TRAIN_LABELS,\n",
    "               nb_epoch = NR_EPOCHS_TO_TRAIN_FOR,               \n",
    "               validation_data = (TEST_IMAGES, TEST_LABELS),\n",
    "               callbacks = [ ModelCheckpoint(\"./model_temp.h5\", monitor='val_loss', verbose= 1, save_best_only=True, mode='min')\n",
    "                 ]\n",
    "      )\n",
    "```\n",
    "Here's what they mean:\n",
    "1. TRAIN_IMAGES is the NumPy array consisting of training images you have just created\n",
    "2. TRAIN_LABELS is the NumPy array consisting of training labels you have just created\n",
    "3. NR_EPOCHS_TO_TRAIN_FOR is the number of epochs for which you wish to train the model\n",
    "4. TEST_IMAGES is the NumPy array consisting of test images you have just created\n",
    "5. TEST_LABELS is the NumPy array consisting of test labels you have just created\n",
    "\n",
    "The callback at the end ***ModelCheckpoint*** will make sure to save at the path specified the best model from all the epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/model_training_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save best weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want now is to load the best weights from whatever epoch happened to yield the best results and save them at another location, such that we won't risk of overriding them when running another training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "We have already provided code for loading the weights. Please use the ***save_weights*** method to save them at another location of your choosing\n",
    "\n",
    "```python\n",
    "model.save_weights(\"./my_model.h5\")\n",
    "```\n",
    "\n",
    "Don't forget to add the ***.h5*** extension at the end !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./model_temp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/weights_save_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use these weights in another Jupyter Notebook in which we'll comunicate with the Self-Driving Car Simulator. The only thing that we need to do is to save the network's architecture to a file, such that we don't have to reconstruct it programatically again.\n",
    "\n",
    "We have provided the ***save_model_to_json*** helper method which is basically just a wraper over Keras's ***model.to_json()***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model_to_json(model, json_path):\n",
    "    model_json = model.to_json()\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to call the method decribed above and pass it the trained model and the json path\n",
    "\n",
    "```python\n",
    "save_model_to_json(MODEL, JSON_PATH)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Answer](http://localhost:8887/edit/clujai_workspace/clujAI-self-driving-car-workshop/answers/json_save_answer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Congratulations\n",
    "\n",
    "You have successfully trained a Self-Driving Car Neural Network. Time to test it on the track and see how it performs. \n",
    "\n",
    "In order to do this, please open the Jupyter Notebook called \"Drive-Autonomous.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
